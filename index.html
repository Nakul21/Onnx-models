<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Text Extract</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 600px;
            margin: 0 auto;
            padding: 20px;
            text-align: center;
        }
        #timer {
            font-size: 1.5em;
            margin-top: 10px;
            color: #333;
        }
        #imagePreview {
            max-width: 100%;
            max-height: 300px;
            margin-top: 10px;
            border: 1px solid #ddd;
        }
        #extractButton {
            margin-top: 10px;
            padding: 10px 20px;
            background-color: #4CAF50;
            color: white;
            border: none;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <h1>OCR Text Extractor</h1>
    <input type="file" id="imageUpload" accept="image/*">
    <img id="imagePreview" alt="Image Preview" style="display: none;">
    <button id="extractButton" style="margin-top: 10px;">Extract Text</button>
    <div id="timer">00:00:00</div>
    <canvas id="canvas" style="display: none;"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script>
        // Ensure Module is defined before OpenCV script loads
        var Module = {
            preRun: [],
            postRun: [],
            print: console.log,
            printErr: console.error,
            onRuntimeInitialized: function() {
                console.log('OpenCV.js runtime initialized');
            }
        };
    </script>
    <script src="https://docs.opencv.org/4.5.2/opencv.js"></script>

    <script>
        let startTime;
        let timerInterval;

        function startTimer() {
            startTime = new Date();
            timerInterval = setInterval(updateTimer, 1000);
        }

        function stopTimer() {
            clearInterval(timerInterval);
        }

        function updateTimer() {
            const currentTime = new Date();
            const timeDifference = currentTime - startTime;
            const seconds = Math.floor(timeDifference / 1000) % 60;
            const minutes = Math.floor(timeDifference / (1000 * 60)) % 60;
            const hours = Math.floor(timeDifference / (1000 * 60 * 60));
            document.getElementById('timer').innerText = `${pad(hours)}:${pad(minutes)}:${pad(seconds)}`;
        }

        function pad(value) {
            return value < 10 ? `0${value}` : value;
        }

        async function runDetectionModel(imageData) {
            try {
                // Note: Replace with actual path to your detection model
                const session = await ort.InferenceSession.create('models/rep_fast_base.onnx');
                const image = cv.imdecode(imageData);
                const inputTensor = preprocessImageForDetection(image);
                const feeds = { 'input': inputTensor };
                const results = await session.run(feeds);
                return postprocessDetectionResults(results);
            } catch (error) {
                console.error('Detection model error:', error);
                return [];
            }
        }

        async function runRecognitionModel(croppedImages) {
            try {
                // Note: Replace with actual path to your recognition model
                const session = await ort.InferenceSession.create('models/parseq_dynamic.onnx');
                const results = [];
                for (const croppedImage of croppedImages) {
                    const inputTensor = preprocessImageForRecognition(croppedImage);
                    const feeds = { 'input': inputTensor };
                    const result = await session.run(feeds);
                    results.push(postprocessRecognitionResult(result));
                }
                return results;
            } catch (error) {
                console.error('Recognition model error:', error);
                return [];
            }
        }

        function preprocessImageForDetection(image) {
            const resizedImage = new cv.Mat();
            cv.resize(image, resizedImage, new cv.Size(1024, 1024));
            
            const normalizedImage = new cv.Mat();
            resizedImage.convertTo(normalizedImage, cv.CV_32F, 1/255.0);
            
            const channels = new cv.MatVector();
            cv.split(normalizedImage, channels);
            
            const tensor = new ort.Tensor('float32', 
                new Float32Array(channels.get(0).data), 
                [1, 3, 1024, 1024]
            );
            
            return tensor;
        }

        function preprocessImageForRecognition(image) {
            const resizedImage = new cv.Mat();
            cv.resize(image, resizedImage, new cv.Size(128, 32));
            
            const normalizedImage = new cv.Mat();
            resizedImage.convertTo(normalizedImage, cv.CV_32F, 1/255.0);
            
            const channels = new cv.MatVector();
            cv.split(normalizedImage, channels);
            
            const tensor = new ort.Tensor('float32', 
                new Float32Array(channels.get(0).data), 
                [1, 3, 32, 128]
            );
            
            return tensor;
        }

        function postprocessDetectionResults(results) {
            // This is a placeholder - you'll need to adjust based on your actual model output
            const boundingBoxes = results['output'].data.map(box => ({
                x: Math.max(0, box[0]),
                y: Math.max(0, box[1]),
                width: Math.abs(box[2] - box[0]),
                height: Math.abs(box[3] - box[1])
            }));
            return boundingBoxes;
        }

        function postprocessRecognitionResult(result) {
            // This is a placeholder - you'll need to adjust based on your actual model output
            const text = result['output'].data.map(charCode => String.fromCharCode(charCode)).join('');
            return text;
        }

        async function main(file) {
            try {
                const reader = new FileReader();
                reader.onload = async (event) => {
                    const imageData = new Uint8Array(event.target.result);
                    const boundingBoxes = await runDetectionModel(imageData);
                    
                    const image = cv.imdecode(imageData);
                    const croppedImages = boundingBoxes.map(box => {
                        const rect = new cv.Rect(
                            Math.max(0, box.x), 
                            Math.max(0, box.y), 
                            Math.max(1, box.width), 
                            Math.max(1, box.height)
                        );
                        return image.roi(rect);
                    });

                    const recognizedTexts = await runRecognitionModel(croppedImages);
                    
                    stopTimer();
                    alert(`OCR Results:\n${recognizedTexts.join('\n')}`);

                    // Clean up
                    image.delete();
                    croppedImages.forEach(img => img.delete());
                };
                reader.readAsArrayBuffer(file);

                // Set the image preview
                const imgPreview = document.getElementById('imagePreview');
                imgPreview.src = URL.createObjectURL(file);
                imgPreview.style.display = 'block';
            } catch (error) {
                console.error('OCR processing error:', error);
                stopTimer();
                alert('Error processing image');
            }
        }

        document.getElementById('imageUpload').addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                // Reset preview
                const imgPreview = document.getElementById('imagePreview');
                imgPreview.src = '';
                imgPreview.style.display = 'none';
            } else {
                console.log('No file selected');
            }
        });

        document.getElementById('extractButton').addEventListener('click', () => {
            const file = document.getElementById('imageUpload').files[0];
            if (file) {
                startTimer();
                main(file);
            } else {
                alert('Please select an image first.');
            }
        });

        // Ensure OpenCV and models are ready
        document.addEventListener('DOMContentLoaded', () => {
            if (typeof cv !== 'undefined' && typeof ort !== 'undefined') {
                console.log('OpenCV.js and ONNX Runtime are ready');
            } else {
                console.error('Required libraries not loaded');
            }
        });
    </script>
</body>
</html>
